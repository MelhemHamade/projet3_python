{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec8c8a6-a410-43a5-a1a1-3927f5386c88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6193c6-9813-47ba-ac70-fbf67def528d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Contexte\n",
    "Pour atteindre l'objectif de ville neutre en émissions de carbone en 2050, la ville de Seattle s’intéresse de près aux émissions des bâtiments non destinés à l’habitation.\n",
    "Des relevés minutieux ont été effectués en 2015 et en 2016. Cependant, ces relevés sont coûteux à obtenir, et à partir de ceux déjà réalisés, nous devons tenter de prédire les émissions de CO2 et la consommation totale d’énergie de bâtiments pour lesquels elles n’ont pas encore été mesurées.\n",
    "\n",
    "Dans cette première partie, nous allons réaliser une courte analyse exploratoire après avoir nettoyé les données si besoin. Le but sera de déterminer les variables pertinentes ou d'en créer de nouvelles (feature engineering).\n",
    "\n",
    "\n",
    "Sommaire\n",
    "1. Chargement et adaptation des données de relèves\n",
    "1.1. Comparaison des colonnes des datasets\n",
    "1.2. Décompactage des données de localisation de 2015\n",
    "1.3. Description et nettoyage des données\n",
    "2. Analyse exploratoire & Feature Engineering\n",
    "2.1. Les types de bâtiments\n",
    "2.2. Les années de construction\n",
    "2.3. Les corrélations linéaires\n",
    "2.4. Analyse des variables à prédire\n",
    "3. Dernières étapes de nettoyage\n",
    "4. Projection des établissements sur la carte de Seattle\n",
    "\n",
    "\n",
    "1. Chargement et adaptation des données de relèves\n",
    "In [1]:\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.color_palette(\"crest\", as_cmap=True)\n",
    "\n",
    "#Lecture du dossier data Kaggle\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "/kaggle/input/sea-building-energy-benchmarking/2016-building-energy-benchmarking.csv\n",
    "/kaggle/input/sea-building-energy-benchmarking/socrata_metadata_2016-building-energy-benchmarking.json\n",
    "/kaggle/input/sea-building-energy-benchmarking/2015-building-energy-benchmarking.csv\n",
    "/kaggle/input/sea-building-energy-benchmarking/socrata_metadata_2015-building-energy-benchmarking.json\n",
    "In [2]:\n",
    "\n",
    "\n",
    "data_2015 = pd.read_csv(\"../input/sea-building-energy-benchmarking/2015-building-energy-benchmarking.csv\")\n",
    "data_2015.head()\n",
    "Out[2]:\n",
    "\n",
    "OSEBuildingID\n",
    "DataYear\n",
    "BuildingType\n",
    "PrimaryPropertyType\n",
    "PropertyName\n",
    "TaxParcelIdentificationNumber\n",
    "Location\n",
    "CouncilDistrictCode\n",
    "Neighborhood\n",
    "YearBuilt\n",
    "...\n",
    "GHGEmissionsIntensity(kgCO2e/ft2)\n",
    "DefaultData\n",
    "Comment\n",
    "ComplianceStatus\n",
    "Outlier\n",
    "2010 Census Tracts\n",
    "Seattle Police Department Micro Community Policing Plan Areas\n",
    "City Council Districts\n",
    "SPD Beats\n",
    "Zip Codes\n",
    "0\n",
    "1\n",
    "2015\n",
    "NonResidential\n",
    "Hotel\n",
    "MAYFLOWER PARK HOTEL\n",
    "659000030\n",
    "{'latitude': '47.61219025', 'longitude': '-122...\n",
    "7\n",
    "DOWNTOWN\n",
    "1927\n",
    "...\n",
    "2.64\n",
    "No\n",
    "NaN\n",
    "Compliant\n",
    "NaN\n",
    "NaN\n",
    "14.0\n",
    "NaN\n",
    "31.0\n",
    "18081\n",
    "1\n",
    "2\n",
    "2015\n",
    "NonResidential\n",
    "Hotel\n",
    "PARAMOUNT HOTEL\n",
    "659000220\n",
    "{'latitude': '47.61310583', 'longitude': '-122...\n",
    "7\n",
    "DOWNTOWN\n",
    "1996\n",
    "...\n",
    "2.38\n",
    "No\n",
    "NaN\n",
    "Compliant\n",
    "NaN\n",
    "NaN\n",
    "14.0\n",
    "NaN\n",
    "31.0\n",
    "18081\n",
    "2\n",
    "3\n",
    "2015\n",
    "NonResidential\n",
    "Hotel\n",
    "WESTIN HOTEL\n",
    "659000475\n",
    "{'latitude': '47.61334897', 'longitude': '-122...\n",
    "7\n",
    "DOWNTOWN\n",
    "1969\n",
    "...\n",
    "1.92\n",
    "Yes\n",
    "NaN\n",
    "Compliant\n",
    "NaN\n",
    "NaN\n",
    "56.0\n",
    "NaN\n",
    "31.0\n",
    "18081\n",
    "3\n",
    "5\n",
    "2015\n",
    "NonResidential\n",
    "Hotel\n",
    "HOTEL MAX\n",
    "659000640\n",
    "{'latitude': '47.61421585', 'longitude': '-122...\n",
    "7\n",
    "DOWNTOWN\n",
    "1926\n",
    "...\n",
    "31.38\n",
    "No\n",
    "NaN\n",
    "Compliant\n",
    "High Outlier\n",
    "NaN\n",
    "56.0\n",
    "NaN\n",
    "31.0\n",
    "18081\n",
    "4\n",
    "8\n",
    "2015\n",
    "NonResidential\n",
    "Hotel\n",
    "WARWICK SEATTLE HOTEL\n",
    "659000970\n",
    "{'latitude': '47.6137544', 'longitude': '-122....\n",
    "7\n",
    "DOWNTOWN\n",
    "1980\n",
    "...\n",
    "4.02\n",
    "No\n",
    "NaN\n",
    "Compliant\n",
    "NaN\n",
    "NaN\n",
    "56.0\n",
    "NaN\n",
    "31.0\n",
    "19576\n",
    "5 rows × 47 columns\n",
    "In [3]:\n",
    "\n",
    "\n",
    "data_2016 = pd.read_csv(\"../input/sea-building-energy-benchmarking/2016-building-energy-benchmarking.csv\")\n",
    "data_2016.head()\n",
    "Out[3]:\n",
    "\n",
    "OSEBuildingID\n",
    "DataYear\n",
    "BuildingType\n",
    "PrimaryPropertyType\n",
    "PropertyName\n",
    "Address\n",
    "City\n",
    "State\n",
    "ZipCode\n",
    "TaxParcelIdentificationNumber\n",
    "...\n",
    "Electricity(kWh)\n",
    "Electricity(kBtu)\n",
    "NaturalGas(therms)\n",
    "NaturalGas(kBtu)\n",
    "DefaultData\n",
    "Comments\n",
    "ComplianceStatus\n",
    "Outlier\n",
    "TotalGHGEmissions\n",
    "GHGEmissionsIntensity\n",
    "0\n",
    "1\n",
    "2016\n",
    "NonResidential\n",
    "Hotel\n",
    "Mayflower park hotel\n",
    "405 Olive way\n",
    "Seattle\n",
    "WA\n",
    "98101.0\n",
    "0659000030\n",
    "...\n",
    "1.156514e+06\n",
    "3946027.0\n",
    "12764.52930\n",
    "1276453.0\n",
    "False\n",
    "NaN\n",
    "Compliant\n",
    "NaN\n",
    "249.98\n",
    "2.83\n",
    "1\n",
    "2\n",
    "2016\n",
    "NonResidential\n",
    "Hotel\n",
    "Paramount Hotel\n",
    "724 Pine street\n",
    "Seattle\n",
    "WA\n",
    "98101.0\n",
    "0659000220\n",
    "...\n",
    "9.504252e+05\n",
    "3242851.0\n",
    "51450.81641\n",
    "5145082.0\n",
    "False\n",
    "NaN\n",
    "Compliant\n",
    "NaN\n",
    "295.86\n",
    "2.86\n",
    "2\n",
    "3\n",
    "2016\n",
    "NonResidential\n",
    "Hotel\n",
    "5673-The Westin Seattle\n",
    "1900 5th Avenue\n",
    "Seattle\n",
    "WA\n",
    "98101.0\n",
    "0659000475\n",
    "...\n",
    "1.451544e+07\n",
    "49526664.0\n",
    "14938.00000\n",
    "1493800.0\n",
    "False\n",
    "NaN\n",
    "Compliant\n",
    "NaN\n",
    "2089.28\n",
    "2.19\n",
    "3\n",
    "5\n",
    "2016\n",
    "NonResidential\n",
    "Hotel\n",
    "HOTEL MAX\n",
    "620 STEWART ST\n",
    "Seattle\n",
    "WA\n",
    "98101.0\n",
    "0659000640\n",
    "...\n",
    "8.115253e+05\n",
    "2768924.0\n",
    "18112.13086\n",
    "1811213.0\n",
    "False\n",
    "NaN\n",
    "Compliant\n",
    "NaN\n",
    "286.43\n",
    "4.67\n",
    "4\n",
    "8\n",
    "2016\n",
    "NonResidential\n",
    "Hotel\n",
    "WARWICK SEATTLE HOTEL (ID8)\n",
    "401 LENORA ST\n",
    "Seattle\n",
    "WA\n",
    "98121.0\n",
    "0659000970\n",
    "...\n",
    "1.573449e+06\n",
    "5368607.0\n",
    "88039.98438\n",
    "8803998.0\n",
    "False\n",
    "NaN\n",
    "Compliant\n",
    "NaN\n",
    "505.01\n",
    "2.88\n",
    "5 rows × 46 columns\n",
    "\n",
    "\n",
    "Après avoir visualisé les premières lignes de ces 2 datasets, on remarque déjà que les colonnes ne sont pas identiques. Identifions les différences :\n",
    "\n",
    "\n",
    "1.1. Comparaison des colonnes des datasets\n",
    "In [4]:\n",
    "\n",
    "\n",
    "def compare_colums(df1,df2):\n",
    "    columns_1 = list(df1.columns) \n",
    "    columns_2 = list(df2.columns)\n",
    "    same_columns=[]\n",
    "    diff_columns_2=[]\n",
    "    diff_columns_1=[]\n",
    "\n",
    "    for col in columns_2:\n",
    "        if col in columns_1:\n",
    "            same_columns.append(col)\n",
    "        else:\n",
    "            diff_columns_2.append(col)\n",
    "    for col in columns_1:\n",
    "        if col not in columns_2:\n",
    "            diff_columns_1.append(col)\n",
    "    return diff_columns_1, diff_columns_2\n",
    "In [5]:\n",
    "\n",
    "\n",
    "diff_columns_2015, diff_columns_2016 = compare_colums(data_2015,data_2016)\n",
    "diff_columns_2015\n",
    "Out[5]:\n",
    "['Location',\n",
    " 'OtherFuelUse(kBtu)',\n",
    " 'GHGEmissions(MetricTonsCO2e)',\n",
    " 'GHGEmissionsIntensity(kgCO2e/ft2)',\n",
    " 'Comment',\n",
    " '2010 Census Tracts',\n",
    " 'Seattle Police Department Micro Community Policing Plan Areas',\n",
    " 'City Council Districts',\n",
    " 'SPD Beats',\n",
    " 'Zip Codes']\n",
    "In [6]:\n",
    "\n",
    "\n",
    "diff_columns_2016\n",
    "Out[6]:\n",
    "['Address',\n",
    " 'City',\n",
    " 'State',\n",
    " 'ZipCode',\n",
    " 'Latitude',\n",
    " 'Longitude',\n",
    " 'Comments',\n",
    " 'TotalGHGEmissions',\n",
    " 'GHGEmissionsIntensity']\n",
    "\n",
    "\n",
    "Les données de localisation ont évolué entre 2015 et 2016. On retrouve en plus l'adresse, la ville et la localisation GPS a été segmentée en Latitude et Longitude. Certaines autres variables comme GHGEmissions(MetricTonsCO2e) ont changé de nom (il faudra vérifier si l'odre de grandeur des données à changer comparativement à TotalGHGEmissions de 2016).\n",
    "\n",
    "\n",
    "1.2. Décompactage des données de localisation de 2015\n",
    "In [7]:\n",
    "\n",
    "\n",
    "data_2015['Location'][0]\n",
    "Out[7]:\n",
    "'{\\'latitude\\': \\'47.61219025\\', \\'longitude\\': \\'-122.33799744\\', \\'human_address\\': \\'{\"address\": \"405 OLIVE WAY\", \"city\": \"SEATTLE\", \"state\": \"WA\", \"zip\": \"98101\"}\\'}'\n",
    "\n",
    "\n",
    "On remarque que les données de localisation pour le jeu de données de 2015 sont \"compactées\" dans une sorte de double dictionnaire. Nous allons donc travailler cette variable pour extraire chacune des variables imbriquées :\n",
    "In [8]:\n",
    "\n",
    "\n",
    "import ast\n",
    "data_2015['Location'] = [ast.literal_eval(str(item)) for index, item in data_2015.Location.iteritems()]\n",
    "data_2015 = pd.concat([data_2015.drop(['Location'], axis=1), data_2015['Location'].apply(pd.Series)], axis=1)\n",
    "data_2015['human_address'] = [ast.literal_eval(str(item)) for index, item in data_2015.human_address.iteritems()]\n",
    "data_2015 = pd.concat([data_2015.drop(['human_address'], axis=1), data_2015['human_address'].apply(pd.Series)], axis=1)\n",
    "data_2015.head()\n",
    "Out[8]:\n",
    "\n",
    "OSEBuildingID\n",
    "DataYear\n",
    "BuildingType\n",
    "PrimaryPropertyType\n",
    "PropertyName\n",
    "TaxParcelIdentificationNumber\n",
    "CouncilDistrictCode\n",
    "Neighborhood\n",
    "YearBuilt\n",
    "NumberofBuildings\n",
    "...\n",
    "Seattle Police Department Micro Community Policing Plan Areas\n",
    "City Council Districts\n",
    "SPD Beats\n",
    "Zip Codes\n",
    "latitude\n",
    "longitude\n",
    "address\n",
    "city\n",
    "state\n",
    "zip\n",
    "0\n",
    "1\n",
    "2015\n",
    "NonResidential\n",
    "Hotel\n",
    "MAYFLOWER PARK HOTEL\n",
    "659000030\n",
    "7\n",
    "DOWNTOWN\n",
    "1927\n",
    "1\n",
    "...\n",
    "14.0\n",
    "NaN\n",
    "31.0\n",
    "18081\n",
    "47.61219025\n",
    "-122.33799744\n",
    "405 OLIVE WAY\n",
    "SEATTLE\n",
    "WA\n",
    "98101\n",
    "1\n",
    "2\n",
    "2015\n",
    "NonResidential\n",
    "Hotel\n",
    "PARAMOUNT HOTEL\n",
    "659000220\n",
    "7\n",
    "DOWNTOWN\n",
    "1996\n",
    "1\n",
    "...\n",
    "14.0\n",
    "NaN\n",
    "31.0\n",
    "18081\n",
    "47.61310583\n",
    "-122.33335756\n",
    "724 PINE ST\n",
    "SEATTLE\n",
    "WA\n",
    "98101\n",
    "2\n",
    "3\n",
    "2015\n",
    "NonResidential\n",
    "Hotel\n",
    "WESTIN HOTEL\n",
    "659000475\n",
    "7\n",
    "DOWNTOWN\n",
    "1969\n",
    "1\n",
    "...\n",
    "56.0\n",
    "NaN\n",
    "31.0\n",
    "18081\n",
    "47.61334897\n",
    "-122.33769944\n",
    "1900 5TH AVE\n",
    "SEATTLE\n",
    "WA\n",
    "98101\n",
    "3\n",
    "5\n",
    "2015\n",
    "NonResidential\n",
    "Hotel\n",
    "HOTEL MAX\n",
    "659000640\n",
    "7\n",
    "DOWNTOWN\n",
    "1926\n",
    "1\n",
    "...\n",
    "56.0\n",
    "NaN\n",
    "31.0\n",
    "18081\n",
    "47.61421585\n",
    "-122.33660889\n",
    "620 STEWART ST\n",
    "SEATTLE\n",
    "WA\n",
    "98101\n",
    "4\n",
    "8\n",
    "2015\n",
    "NonResidential\n",
    "Hotel\n",
    "WARWICK SEATTLE HOTEL\n",
    "659000970\n",
    "7\n",
    "DOWNTOWN\n",
    "1980\n",
    "1\n",
    "...\n",
    "56.0\n",
    "NaN\n",
    "31.0\n",
    "19576\n",
    "47.6137544\n",
    "-122.3409238\n",
    "401 LENORA ST\n",
    "SEATTLE\n",
    "WA\n",
    "98121\n",
    "5 rows × 52 columns\n",
    "\n",
    "\n",
    "Nous avons à présent les colonnes correspondant à celles de 2016 : latitude, longitude, address, city, state et zip. Renommons les de la même façon :\n",
    "In [9]:\n",
    "\n",
    "\n",
    "data_2015 = data_2015.rename(columns={\"latitude\":\"Latitude\", \"longitude\":\"Longitude\",\n",
    "                                      \"address\":\"Address\", \"city\":\"City\", \n",
    "                                      \"state\":\"State\", \"zip\":\"ZipCode\"})\n",
    "\n",
    "\n",
    "Puis regardons à nouveau les différences de colonnes entre les 2 dataframes :\n",
    "In [10]:\n",
    "\n",
    "\n",
    "diff_columns_2015, diff_columns_2016 = compare_colums(data_2015,data_2016)\n",
    "diff_columns_2015\n",
    "Out[10]:\n",
    "['OtherFuelUse(kBtu)',\n",
    " 'GHGEmissions(MetricTonsCO2e)',\n",
    " 'GHGEmissionsIntensity(kgCO2e/ft2)',\n",
    " 'Comment',\n",
    " '2010 Census Tracts',\n",
    " 'Seattle Police Department Micro Community Policing Plan Areas',\n",
    " 'City Council Districts',\n",
    " 'SPD Beats',\n",
    " 'Zip Codes']\n",
    "In [11]:\n",
    "\n",
    "\n",
    "diff_columns_2016\n",
    "Out[11]:\n",
    "['Comments', 'TotalGHGEmissions', 'GHGEmissionsIntensity']\n",
    "In [12]:\n",
    "\n",
    "\n",
    "print(f\"Description de la variable TotalGHGEmissions 2016 : \\n\\n\",data_2016['TotalGHGEmissions'].describe(),\n",
    "     f\"\\n\\nDescription de la variable GHGEmissions(MetricTonsCO2e) 2015 : \\n\\n\", data_2015['GHGEmissions(MetricTonsCO2e)'].describe())\n",
    "Description de la variable TotalGHGEmissions 2016 : \n",
    "\n",
    " count     3367.000000\n",
    "mean       119.723971\n",
    "std        538.832227\n",
    "min         -0.800000\n",
    "25%          9.495000\n",
    "50%         33.920000\n",
    "75%         93.940000\n",
    "max      16870.980000\n",
    "Name: TotalGHGEmissions, dtype: float64 \n",
    "\n",
    "Description de la variable GHGEmissions(MetricTonsCO2e) 2015 : \n",
    "\n",
    " count     3330.000000\n",
    "mean       110.094102\n",
    "std        409.450179\n",
    "min          0.000000\n",
    "25%          9.265000\n",
    "50%         32.740000\n",
    "75%         88.642500\n",
    "max      11824.890000\n",
    "Name: GHGEmissions(MetricTonsCO2e), dtype: float64\n",
    "\n",
    "\n",
    "Les odres de grandeur des 2 variables sont identiques entre 2015 et 2016. Nous allons donc simplement renomer les colonnes à l'identique. Nous supprimons également les colonnes de 2015 n'ayant pas d'équivalent en 2016:\n",
    "In [13]:\n",
    "\n",
    "\n",
    "data_2015 = data_2015.rename(columns={'GHGEmissions(MetricTonsCO2e)':'TotalGHGEmissions',\n",
    "                                     'GHGEmissionsIntensity(kgCO2e/ft2)':'GHGEmissionsIntensity',\n",
    "                                     'Comment':'Comments'})\n",
    "data_2015.drop(['OtherFuelUse(kBtu)','2010 Census Tracts',\n",
    "                'Seattle Police Department Micro Community Policing Plan Areas',\n",
    "                'City Council Districts','SPD Beats', 'Zip Codes'], axis=1, inplace=True)\n",
    "In [14]:\n",
    "\n",
    "\n",
    "diff_columns_2015, diff_columns_2016 = compare_colums(data_2015,data_2016)\n",
    "print(diff_columns_2015,diff_columns_2016)\n",
    "[] []\n",
    "\n",
    "\n",
    "Les variables des 2 datasets étant à présent identiques, nous allons pouvoir les regrouper en un unique jeu de données :\n",
    "In [15]:\n",
    "\n",
    "\n",
    "data = pd.concat([data_2015[data_2016.columns],data_2016], axis = 0).sort_values([\"DataYear\", \"OSEBuildingID\"])\n",
    "data.shape\n",
    "Out[15]:\n",
    "(6716, 46)\n",
    "\n",
    "\n",
    "1.3. Description et nettoyage des données\n",
    "\n",
    "\n",
    "Il est précisié dans le projet que seuls les bâtiments non destinés à l'habitation seront étudiés. Nous allons donc supprimer toutes les lignes correspondant à des habitations en nous basant sur la variable BuildingType\n",
    "In [16]:\n",
    "\n",
    "\n",
    "data['BuildingType'].unique()\n",
    "Out[16]:\n",
    "array(['NonResidential', 'Nonresidential COS', 'Multifamily MR (5-9)',\n",
    "       'SPS-District K-12', 'Multifamily LR (1-4)', 'Campus',\n",
    "       'Multifamily HR (10+)', 'Nonresidential WA'], dtype=object)\n",
    "In [17]:\n",
    "\n",
    "\n",
    "data = data[~data['BuildingType'].str.contains(\"Multifamily\")]\n",
    "data['BuildingType'].unique()\n",
    "Out[17]:\n",
    "array(['NonResidential', 'Nonresidential COS', 'SPS-District K-12',\n",
    "       'Campus', 'Nonresidential WA'], dtype=object)\n",
    "In [18]:\n",
    "\n",
    "\n",
    "print(\"Le jeu de données compte à présent {} lignes et {} colonnes.\".format(data.shape[0],data.shape[1]))\n",
    "Le jeu de données compte à présent 3318 lignes et 46 colonnes.\n",
    "\n",
    "\n",
    "Nous allons également regarder s'il existe des doublons sur l'identifiant OSEBuildingID. On effet, nos modélisations devront porter sur un bâtiement unique (ce n'est pas une modélisation temporelle). Nous prendrons donc en valeur la moyenne des variables sur les 2 années :\n",
    "In [19]:\n",
    "\n",
    "\n",
    "mean_columns = ['NumberofBuildings', 'NumberofFloors', 'PropertyGFATotal',\n",
    "                'PropertyGFAParking', 'PropertyGFABuilding(s)',\n",
    "                'LargestPropertyUseTypeGFA', 'SecondLargestPropertyUseTypeGFA',\n",
    "                'ThirdLargestPropertyUseTypeGFA', 'ENERGYSTARScore', 'SiteEUI(kBtu/sf)',\n",
    "                'SiteEUIWN(kBtu/sf)', 'SourceEUI(kBtu/sf)', 'SourceEUIWN(kBtu/sf)',\n",
    "                'SiteEnergyUse(kBtu)', 'SiteEnergyUseWN(kBtu)', 'SteamUse(kBtu)',\n",
    "                'Electricity(kWh)', 'Electricity(kBtu)', 'NaturalGas(therms)',\n",
    "                'NaturalGas(kBtu)', 'TotalGHGEmissions', 'GHGEmissionsIntensity']\n",
    "OSEBuilding_means = data[['OSEBuildingID']+mean_columns].groupby('OSEBuildingID').mean()\n",
    "OSEBuilding_means.head()\n",
    "Out[19]:\n",
    "\n",
    "NumberofBuildings\n",
    "NumberofFloors\n",
    "PropertyGFATotal\n",
    "PropertyGFAParking\n",
    "PropertyGFABuilding(s)\n",
    "LargestPropertyUseTypeGFA\n",
    "SecondLargestPropertyUseTypeGFA\n",
    "ThirdLargestPropertyUseTypeGFA\n",
    "ENERGYSTARScore\n",
    "SiteEUI(kBtu/sf)\n",
    "...\n",
    "SourceEUIWN(kBtu/sf)\n",
    "SiteEnergyUse(kBtu)\n",
    "SiteEnergyUseWN(kBtu)\n",
    "SteamUse(kBtu)\n",
    "Electricity(kWh)\n",
    "Electricity(kBtu)\n",
    "NaturalGas(therms)\n",
    "NaturalGas(kBtu)\n",
    "TotalGHGEmissions\n",
    "GHGEmissionsIntensity\n",
    "OSEBuildingID\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "1\n",
    "1.0\n",
    "12.0\n",
    "88434.0\n",
    "0.0\n",
    "88434.0\n",
    "88434.0\n",
    "NaN\n",
    "NaN\n",
    "62.5\n",
    "80.299998\n",
    "...\n",
    "182.050000\n",
    "7103895.25\n",
    "7277224.50\n",
    "2.013457e+06\n",
    "1.118411e+06\n",
    "3816093.5\n",
    "12744.264650\n",
    "1274420.5\n",
    "249.705\n",
    "2.735\n",
    "2\n",
    "1.0\n",
    "11.0\n",
    "103566.0\n",
    "15064.0\n",
    "88502.0\n",
    "83880.0\n",
    "15064.0\n",
    "4622.0\n",
    "56.0\n",
    "94.600002\n",
    "...\n",
    "187.299997\n",
    "8371084.00\n",
    "8715133.50\n",
    "0.000000e+00\n",
    "1.047494e+06\n",
    "3574131.0\n",
    "47970.408205\n",
    "4797033.5\n",
    "279.685\n",
    "2.620\n",
    "3\n",
    "1.0\n",
    "41.0\n",
    "959050.0\n",
    "98359.0\n",
    "860691.0\n",
    "756868.0\n",
    "100000.0\n",
    "0.0\n",
    "30.5\n",
    "96.300000\n",
    "...\n",
    "245.300003\n",
    "72858840.00\n",
    "74721692.00\n",
    "2.061348e+07\n",
    "1.454968e+07\n",
    "49644549.5\n",
    "26018.500000\n",
    "2601850.0\n",
    "2075.380\n",
    "2.055\n",
    "5\n",
    "1.0\n",
    "10.0\n",
    "61320.0\n",
    "0.0\n",
    "61320.0\n",
    "61320.0\n",
    "NaN\n",
    "NaN\n",
    "28.5\n",
    "285.600002\n",
    "...\n",
    "433.600000\n",
    "17511952.00\n",
    "17655122.25\n",
    "1.283648e+07\n",
    "8.115232e+05\n",
    "2768973.5\n",
    "19065.565430\n",
    "1906553.5\n",
    "1111.385\n",
    "18.025\n",
    "8\n",
    "1.0\n",
    "18.0\n",
    "147735.0\n",
    "37230.0\n",
    "110505.0\n",
    "123445.0\n",
    "68009.0\n",
    "0.0\n",
    "71.0\n",
    "117.450002\n",
    "...\n",
    "221.350003\n",
    "14500852.50\n",
    "14867373.00\n",
    "0.000000e+00\n",
    "1.675645e+06\n",
    "5717426.0\n",
    "87835.492190\n",
    "8783551.5\n",
    "506.355\n",
    "3.450\n",
    "5 rows × 22 columns\n",
    "In [20]:\n",
    "\n",
    "\n",
    "duplicate_building = data.drop_duplicates(subset=['OSEBuildingID'], keep='last')\n",
    "duplicate_building.drop(mean_columns, axis=1, inplace=True)\n",
    "data = pd.merge(duplicate_building, OSEBuilding_means, how='left', on='OSEBuildingID')\n",
    "/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py:4315: SettingWithCopyWarning: \n",
    "A value is trying to be set on a copy of a slice from a DataFrame\n",
    "\n",
    "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
    "  errors=errors,\n",
    "\n",
    "\n",
    "Le jeu de données ne compte à présent plus de doublons sur la variable OSEBuildingID.\n",
    "Regardons à présent les infos et descriptions du dataset :\n",
    "In [21]:\n",
    "\n",
    "\n",
    "data.info()\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "Int64Index: 1698 entries, 0 to 1697\n",
    "Data columns (total 46 columns):\n",
    " #   Column                           Non-Null Count  Dtype  \n",
    "---  ------                           --------------  -----  \n",
    " 0   OSEBuildingID                    1698 non-null   int64  \n",
    " 1   DataYear                         1698 non-null   int64  \n",
    " 2   BuildingType                     1698 non-null   object \n",
    " 3   PrimaryPropertyType              1698 non-null   object \n",
    " 4   PropertyName                     1698 non-null   object \n",
    " 5   Address                          1698 non-null   object \n",
    " 6   City                             1698 non-null   object \n",
    " 7   State                            1698 non-null   object \n",
    " 8   ZipCode                          1682 non-null   object \n",
    " 9   TaxParcelIdentificationNumber    1698 non-null   object \n",
    " 10  CouncilDistrictCode              1698 non-null   int64  \n",
    " 11  Neighborhood                     1698 non-null   object \n",
    " 12  Latitude                         1698 non-null   object \n",
    " 13  Longitude                        1698 non-null   object \n",
    " 14  YearBuilt                        1698 non-null   int64  \n",
    " 15  ListOfAllPropertyUseTypes        1690 non-null   object \n",
    " 16  LargestPropertyUseType           1686 non-null   object \n",
    " 17  SecondLargestPropertyUseType     866 non-null    object \n",
    " 18  ThirdLargestPropertyUseType      356 non-null    object \n",
    " 19  YearsENERGYSTARCertified         99 non-null     object \n",
    " 20  DefaultData                      1698 non-null   object \n",
    " 21  Comments                         1 non-null      object \n",
    " 22  ComplianceStatus                 1698 non-null   object \n",
    " 23  Outlier                          19 non-null     object \n",
    " 24  NumberofBuildings                1698 non-null   float64\n",
    " 25  NumberofFloors                   1698 non-null   float64\n",
    " 26  PropertyGFATotal                 1698 non-null   float64\n",
    " 27  PropertyGFAParking               1698 non-null   float64\n",
    " 28  PropertyGFABuilding(s)           1698 non-null   float64\n",
    " 29  LargestPropertyUseTypeGFA        1686 non-null   float64\n",
    " 30  SecondLargestPropertyUseTypeGFA  868 non-null    float64\n",
    " 31  ThirdLargestPropertyUseTypeGFA   361 non-null    float64\n",
    " 32  ENERGYSTARScore                  1154 non-null   float64\n",
    " 33  SiteEUI(kBtu/sf)                 1697 non-null   float64\n",
    " 34  SiteEUIWN(kBtu/sf)               1697 non-null   float64\n",
    " 35  SourceEUI(kBtu/sf)               1697 non-null   float64\n",
    " 36  SourceEUIWN(kBtu/sf)             1697 non-null   float64\n",
    " 37  SiteEnergyUse(kBtu)              1697 non-null   float64\n",
    " 38  SiteEnergyUseWN(kBtu)            1697 non-null   float64\n",
    " 39  SteamUse(kBtu)                   1697 non-null   float64\n",
    " 40  Electricity(kWh)                 1697 non-null   float64\n",
    " 41  Electricity(kBtu)                1697 non-null   float64\n",
    " 42  NaturalGas(therms)               1697 non-null   float64\n",
    " 43  NaturalGas(kBtu)                 1697 non-null   float64\n",
    " 44  TotalGHGEmissions                1697 non-null   float64\n",
    " 45  GHGEmissionsIntensity            1697 non-null   float64\n",
    "dtypes: float64(22), int64(4), object(20)\n",
    "memory usage: 623.5+ KB\n",
    "\n",
    "\n",
    "Dans la visualisation ci-dessus, certaines variables apparaissent déjà comme redondantes :\n",
    "Electricity(kWh) et Electricity(kBtu),\n",
    "NaturalGas(therms) et NaturalGas(kBtu)\n",
    "Les suffixes WN : \"Weather Normalized\" - Ce sont les mesures normalisées avec les conditions climatiques. Dans le cadre de notre analyse, la météo ne rentrera pas en compte.\n",
    "Nous allons donc commencer par supprimer ces variables :\n",
    "In [22]:\n",
    "\n",
    "\n",
    "def search_componant(df, suffix=None):\n",
    "  componant = []\n",
    "  for col in df.columns:\n",
    "      if suffix in col: \n",
    "        componant.append(col)\n",
    "  return componant\n",
    "In [23]:\n",
    "\n",
    "\n",
    "#Suppression des variables WN\n",
    "data.drop(search_componant(data,'WN'), axis=1, inplace=True)\n",
    "In [24]:\n",
    "\n",
    "\n",
    "#Suppression des variables redondantes\n",
    "redundant_features = ['NaturalGas(therms)','Electricity(kWh)']\n",
    "data.drop(redundant_features, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "On remarque également des variables suffixées GFA : Elles représente la surface au sol (Ground Floor Area). Nous les conservons donc pour la suite des analyses.\n",
    "In [25]:\n",
    "\n",
    "\n",
    "data.describe()\n",
    "Out[25]:\n",
    "\n",
    "OSEBuildingID\n",
    "DataYear\n",
    "CouncilDistrictCode\n",
    "YearBuilt\n",
    "NumberofBuildings\n",
    "NumberofFloors\n",
    "PropertyGFATotal\n",
    "PropertyGFAParking\n",
    "PropertyGFABuilding(s)\n",
    "LargestPropertyUseTypeGFA\n",
    "...\n",
    "ThirdLargestPropertyUseTypeGFA\n",
    "ENERGYSTARScore\n",
    "SiteEUI(kBtu/sf)\n",
    "SourceEUI(kBtu/sf)\n",
    "SiteEnergyUse(kBtu)\n",
    "SteamUse(kBtu)\n",
    "Electricity(kBtu)\n",
    "NaturalGas(kBtu)\n",
    "TotalGHGEmissions\n",
    "GHGEmissionsIntensity\n",
    "count\n",
    "1698.000000\n",
    "1698.000000\n",
    "1698.000000\n",
    "1698.000000\n",
    "1698.000000\n",
    "1698.000000\n",
    "1.698000e+03\n",
    "1698.000000\n",
    "1.698000e+03\n",
    "1.686000e+03\n",
    "...\n",
    "361.000000\n",
    "1154.000000\n",
    "1697.000000\n",
    "1697.000000\n",
    "1.697000e+03\n",
    "1.697000e+03\n",
    "1.697000e+03\n",
    "1.697000e+03\n",
    "1697.000000\n",
    "1697.000000\n",
    "mean\n",
    "16339.776207\n",
    "2015.982332\n",
    "4.369258\n",
    "1961.704947\n",
    "1.148704\n",
    "4.101885\n",
    "1.183777e+05\n",
    "13421.728504\n",
    "1.049560e+05\n",
    "9.887040e+04\n",
    "...\n",
    "14719.000829\n",
    "64.951906\n",
    "72.104331\n",
    "176.282793\n",
    "8.457072e+06\n",
    "5.133132e+05\n",
    "5.865634e+06\n",
    "1.971806e+06\n",
    "185.235053\n",
    "1.501859\n",
    "std\n",
    "13811.042261\n",
    "0.131780\n",
    "2.191411\n",
    "32.850343\n",
    "2.810159\n",
    "6.516620\n",
    "2.951875e+05\n",
    "42938.707728\n",
    "2.806832e+05\n",
    "2.757407e+05\n",
    "...\n",
    "36335.391749\n",
    "28.041709\n",
    "73.490710\n",
    "183.783580\n",
    "3.010387e+07\n",
    "5.351773e+06\n",
    "2.069226e+07\n",
    "9.400898e+06\n",
    "745.538021\n",
    "2.266608\n",
    "min\n",
    "1.000000\n",
    "2015.000000\n",
    "1.000000\n",
    "1900.000000\n",
    "0.500000\n",
    "0.000000\n",
    "1.128500e+04\n",
    "-1.000000\n",
    "-8.451000e+03\n",
    "6.455000e+03\n",
    "...\n",
    "0.000000\n",
    "1.000000\n",
    "0.000000\n",
    "0.000000\n",
    "0.000000e+00\n",
    "0.000000e+00\n",
    "7.000000e+00\n",
    "0.000000e+00\n",
    "0.120000\n",
    "0.000000\n",
    "25%\n",
    "584.250000\n",
    "2016.000000\n",
    "2.000000\n",
    "1930.000000\n",
    "1.000000\n",
    "1.000000\n",
    "2.939250e+04\n",
    "0.000000\n",
    "2.833200e+04\n",
    "2.548025e+04\n",
    "...\n",
    "2592.000000\n",
    "46.500000\n",
    "32.900000\n",
    "77.250002\n",
    "1.215360e+06\n",
    "0.000000e+00\n",
    "7.328030e+05\n",
    "0.000000e+00\n",
    "20.150000\n",
    "0.275000\n",
    "50%\n",
    "21161.000000\n",
    "2016.000000\n",
    "4.000000\n",
    "1965.000000\n",
    "1.000000\n",
    "2.000000\n",
    "4.926600e+04\n",
    "0.000000\n",
    "4.739150e+04\n",
    "4.348400e+04\n",
    "...\n",
    "5931.000000\n",
    "72.500000\n",
    "51.700001\n",
    "131.750000\n",
    "2.555917e+06\n",
    "0.000000e+00\n",
    "1.649172e+06\n",
    "4.974050e+05\n",
    "50.215000\n",
    "0.785000\n",
    "75%\n",
    "24601.750000\n",
    "2016.000000\n",
    "7.000000\n",
    "1989.000000\n",
    "1.000000\n",
    "4.000000\n",
    "1.068380e+05\n",
    "0.000000\n",
    "9.524950e+04\n",
    "9.198825e+04\n",
    "...\n",
    "12400.000000\n",
    "88.000000\n",
    "82.450000\n",
    "206.549997\n",
    "6.960904e+06\n",
    "0.000000e+00\n",
    "4.871044e+06\n",
    "1.507822e+06\n",
    "139.630000\n",
    "1.765000\n",
    "max\n",
    "50226.000000\n",
    "2016.000000\n",
    "7.000000\n",
    "2015.000000\n",
    "111.000000\n",
    "99.000000\n",
    "9.320156e+06\n",
    "512608.000000\n",
    "9.320156e+06\n",
    "9.320156e+06\n",
    "...\n",
    "459748.000000\n",
    "100.000000\n",
    "834.400024\n",
    "2620.000000\n",
    "8.739237e+08\n",
    "1.314066e+08\n",
    "6.570744e+08\n",
    "2.979090e+08\n",
    "16870.980000\n",
    "34.090000\n",
    "8 rows × 21 columns\n",
    "\n",
    "\n",
    "Dans le cadre de nos modélisations, les variables à prédire sont la consommation d'énergie du bâtiment (SiteEnergyUse(kBtu)) et ses émissions de CO2 (TotalGHGEmissions). Certaines lignes comportent des manquants sur ces variables, nous allons donc les supprimer :\n",
    "In [26]:\n",
    "\n",
    "\n",
    "data = data[~((data['SiteEnergyUse(kBtu)'].isnull()) | (data['TotalGHGEmissions'].isnull()))]\n",
    "\n",
    "\n",
    "La variable Comments, très peu renseignée également, peux être supprimée :\n",
    "In [27]:\n",
    "\n",
    "\n",
    "data.drop(\"Comments\", axis=1, inplace=True)\n",
    "\n",
    "\n",
    "La variable identifiant les outliers peut être interessante pour nos analyses, cependant, dans la documentation, nous ne savons pas rééllement à quoi correspondent ces outliers. Nous allons donc supprimer les lignes mentionnant ces outliers.\n",
    "In [28]:\n",
    "\n",
    "\n",
    "data = data[~data[\"Outlier\"].isnull()==False]\n",
    "data.drop('Outlier', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "Nous allons pour le moment conserver les autres variables en l'état. Une courte analyse exploratoire nous en apprendra plus sur les données à conserver.\n",
    "\n",
    "\n",
    "2. Analyse exploratoire & Feature Engineering\n",
    "Dans un premier temps, nous allons regarder la répartition des divers types de bâtiments à étudier :\n",
    "2.1. Les types de bâtiments\n",
    "In [29]:\n",
    "\n",
    "\n",
    "building_type = data.groupby(by='BuildingType')['OSEBuildingID'].nunique()\n",
    "\n",
    "font_title = {'family': 'serif',\n",
    "              'color':  '#1d479b',\n",
    "              'weight': 'bold',\n",
    "              'size': 18,\n",
    "             }\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "ax.pie(building_type.values, labels=building_type.index, \n",
    "       autopct='%1.1f%%', shadow=True, startangle=30,\n",
    "       textprops=dict(color=\"black\",size=12, weight=\"bold\"))\n",
    "ax.axis('equal')\n",
    "ax.set_title(\"Répartition des types de bâtiments du Dataset\", fontdict=font_title)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "la majeur partie des bâtiments sont typés \"NonResidential\". Nous pouvons visualiser les diverses catégories représentées dans ce type de bâtiments :\n",
    "In [30]:\n",
    "\n",
    "\n",
    "data.loc[(data['BuildingType']==\"NonResidential\"),'PrimaryPropertyType'].value_counts()\n",
    "Out[30]:\n",
    "Small- and Mid-Sized Office    290\n",
    "Other                          189\n",
    "Warehouse                      180\n",
    "Large Office                   168\n",
    "Mixed Use Property             103\n",
    "Retail Store                    92\n",
    "Hotel                           75\n",
    "Worship Facility                70\n",
    "Distribution Center             51\n",
    "Medical Office                  41\n",
    "Supermarket / Grocery Store     40\n",
    "K-12 School                     39\n",
    "Self-Storage Facility           28\n",
    "Residence Hall                  21\n",
    "Senior Care Community           20\n",
    "University                      17\n",
    "Refrigerated Warehouse          12\n",
    "Restaurant                      11\n",
    "Laboratory                      10\n",
    "Hospital                        10\n",
    "Non-Refrigerated Warehouse       2\n",
    "Low-Rise Multifamily             1\n",
    "Restaurant\\n                     1\n",
    "Name: PrimaryPropertyType, dtype: int64\n",
    "\n",
    "\n",
    "Ici, on remarque que des catégories sont des doublons avec un caractère d'échappement. Nous allons corriger ce problème :\n",
    "In [31]:\n",
    "\n",
    "\n",
    "import re\n",
    "regex = re.compile(r'[\\n\\r\\t]')\n",
    "data['PrimaryPropertyType'] = [regex.sub(\"\", item) for index, item in data.PrimaryPropertyType.iteritems()]\n",
    "data.loc[(data['BuildingType']==\"NonResidential\"),'PrimaryPropertyType'].value_counts()\n",
    "Out[31]:\n",
    "Small- and Mid-Sized Office    290\n",
    "Other                          189\n",
    "Warehouse                      180\n",
    "Large Office                   168\n",
    "Mixed Use Property             103\n",
    "Retail Store                    92\n",
    "Hotel                           75\n",
    "Worship Facility                70\n",
    "Distribution Center             51\n",
    "Medical Office                  41\n",
    "Supermarket / Grocery Store     40\n",
    "K-12 School                     39\n",
    "Self-Storage Facility           28\n",
    "Residence Hall                  21\n",
    "Senior Care Community           20\n",
    "University                      17\n",
    "Refrigerated Warehouse          12\n",
    "Restaurant                      12\n",
    "Laboratory                      10\n",
    "Hospital                        10\n",
    "Non-Refrigerated Warehouse       2\n",
    "Low-Rise Multifamily             1\n",
    "Name: PrimaryPropertyType, dtype: int64\n",
    "\n",
    "\n",
    "Les bureaux de petite et moyenne taille représentent la plus grande part des bâtiments non résidentiels.\n",
    "2.2. Les années de construction\n",
    "Nous allons regarder les distribution des années de construction des bâtiments de Seattle :\n",
    "In [32]:\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "ax = sns.histplot(data=data, x='YearBuilt', bins=int((data.YearBuilt.max() - data.YearBuilt.min())/5))\n",
    "ax.set_xlabel(\"Année de construction\")\n",
    "ax.set_ylabel(\"Nombre de bâtiments\")\n",
    "plt.title(f\"Distribution des années de construction des bâtiments\\n\", fontdict=font_title)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "Plus que l'année de construction, il serait intéressant de traiter l'age des bâtiments pour réduire la dispersion des données et lier l'année des relevés. Nous allons donc créer cette nouvelle variable et supprimer l'année de construction :\n",
    "In [33]:\n",
    "\n",
    "\n",
    "data['BuildingAge'] = data['DataYear'] - data['YearBuilt']\n",
    "data.drop('YearBuilt', axis=1, inplace=True)\n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "ax = sns.histplot(data=data, x='BuildingAge', bins=int((data.BuildingAge.max() - data.BuildingAge.min())/5))\n",
    "ax.set_xlabel(\"Age du bâtiment\")\n",
    "ax.set_ylabel(\"Nombre de bâtiments\")\n",
    "plt.title(f\"Distribution de l'âge des bâtiments\\n\", fontdict=font_title)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "2.3. Les corrélations linéaires\n",
    "In [34]:\n",
    "\n",
    "\n",
    "corr = data.corr()\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "ax = sns.heatmap(corr, annot=True, fmt=\".2f\", annot_kws={'size':8}, \n",
    "                 mask=mask, center=0, cmap=\"coolwarm\")\n",
    "plt.title(f\"Heatmap des corrélations linéaires\\n\", \n",
    "          fontdict=font_title)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "Pour les varaibles à prédire TotalGHGEmissions et SiteEnergyUse(kBtu), on remarque des corrélations linéaires quasi similaires avec les variables de relevés (les consommations) mais également avec le nombre de batiments ou d'étages ains que les surfaces au sol.\n",
    "On remarque sur ce Heatmap de fortes corrélations linéaires entre variables. Ces corrélations peuvent amener des problèmes de colinéarité dans nos futurs modèles. Isolons donc les paires de variables avec des corrélations de Pearson supérieurs à 0.7 :\n",
    "In [35]:\n",
    "\n",
    "\n",
    "threshold = 0.7\n",
    "corr_pairs = corr.unstack().sort_values(kind=\"quicksort\")\n",
    "strong_corr = (pd.DataFrame(corr_pairs[(abs(corr_pairs) > threshold)])\n",
    "               .reset_index().rename(columns={0:'corr_coeff'}))\n",
    "strong_corr = strong_corr[(strong_corr.index%2 == 0) & (strong_corr['level_0'] != strong_corr['level_1'])]\n",
    "strong_corr.sort_values('corr_coeff', ascending=False)\n",
    "Out[35]:\n",
    "\n",
    "level_0\n",
    "level_1\n",
    "corr_coeff\n",
    "44\n",
    "PropertyGFABuilding(s)\n",
    "PropertyGFATotal\n",
    "0.990146\n",
    "42\n",
    "PropertyGFABuilding(s)\n",
    "LargestPropertyUseTypeGFA\n",
    "0.983214\n",
    "40\n",
    "PropertyGFATotal\n",
    "LargestPropertyUseTypeGFA\n",
    "0.978200\n",
    "38\n",
    "Electricity(kBtu)\n",
    "SiteEnergyUse(kBtu)\n",
    "0.956707\n",
    "36\n",
    "SourceEUI(kBtu/sf)\n",
    "SiteEUI(kBtu/sf)\n",
    "0.951789\n",
    "34\n",
    "Electricity(kBtu)\n",
    "LargestPropertyUseTypeGFA\n",
    "0.886509\n",
    "32\n",
    "PropertyGFABuilding(s)\n",
    "Electricity(kBtu)\n",
    "0.876935\n",
    "30\n",
    "Electricity(kBtu)\n",
    "PropertyGFATotal\n",
    "0.867333\n",
    "28\n",
    "SiteEnergyUse(kBtu)\n",
    "TotalGHGEmissions\n",
    "0.862087\n",
    "26\n",
    "SiteEnergyUse(kBtu)\n",
    "LargestPropertyUseTypeGFA\n",
    "0.845066\n",
    "24\n",
    "LargestPropertyUseTypeGFA\n",
    "NumberofBuildings\n",
    "0.830232\n",
    "22\n",
    "PropertyGFABuilding(s)\n",
    "SiteEnergyUse(kBtu)\n",
    "0.824377\n",
    "20\n",
    "NumberofBuildings\n",
    "PropertyGFABuilding(s)\n",
    "0.815326\n",
    "18\n",
    "PropertyGFATotal\n",
    "SiteEnergyUse(kBtu)\n",
    "0.810407\n",
    "16\n",
    "PropertyGFATotal\n",
    "SecondLargestPropertyUseTypeGFA\n",
    "0.801618\n",
    "14\n",
    "PropertyGFABuilding(s)\n",
    "SecondLargestPropertyUseTypeGFA\n",
    "0.788654\n",
    "12\n",
    "Electricity(kBtu)\n",
    "NumberofBuildings\n",
    "0.775949\n",
    "10\n",
    "NumberofBuildings\n",
    "PropertyGFATotal\n",
    "0.775589\n",
    "8\n",
    "LargestPropertyUseTypeGFA\n",
    "SecondLargestPropertyUseTypeGFA\n",
    "0.767007\n",
    "6\n",
    "SiteEnergyUse(kBtu)\n",
    "ThirdLargestPropertyUseTypeGFA\n",
    "0.757212\n",
    "4\n",
    "TotalGHGEmissions\n",
    "NaturalGas(kBtu)\n",
    "0.736970\n",
    "2\n",
    "NumberofBuildings\n",
    "SiteEnergyUse(kBtu)\n",
    "0.724128\n",
    "0\n",
    "SiteEUI(kBtu/sf)\n",
    "GHGEmissionsIntensity\n",
    "0.703791\n",
    "\n",
    "\n",
    "On remarque que les variables suffixées GFA présentent de fortes corrélations avec plusieurs autres variables. Nous allons donc créer de nouvelles variables pour tenter de gommer ces corrélations linéaires :\n",
    "In [36]:\n",
    "\n",
    "\n",
    "def split_words(df, column = None):\n",
    "  list_words = set()\n",
    "  for word in df[column].str.split(','):\n",
    "    if isinstance(word, float):\n",
    "      continue\n",
    "    list_words = set().union(word, list_words)\n",
    "  return list(list_words)\n",
    "\n",
    "list_use_type = split_words(data, 'ListOfAllPropertyUseTypes')\n",
    "print(\"Nombre de type d'usages dans la base : {}\".format(len(list_use_type)))\n",
    "Nombre de type d'usages dans la base : 117\n",
    "\n",
    "\n",
    "Réaliser un OneHotEncoder sur 117 types d'usage ne serait pas oportun. Nous allons donc créer une variable nous donnant le nombre total d'usage du bâtiment, puis supprimer la liste complète des usages :\n",
    "In [37]:\n",
    "\n",
    "\n",
    "data['TotalUseTypeNumber'] = [str(word).count(\",\") + 1 for word in data['ListOfAllPropertyUseTypes'].str.split(',')]\n",
    "data.drop('ListOfAllPropertyUseTypes', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "Nous allons à présent convertir les différentes surfaces (Buildings et Parking) en pourcentage de la surface totale et nous conserverons uniquement ces 2 variables en supprimant les variables LargestPropertyUseTypeGFA, SecondLargestPropertyUseTypeGFA, ThirdLargestPropertyUseTypeGFA :\n",
    "In [38]:\n",
    "\n",
    "\n",
    "gfa_features = search_componant(data, suffix='GFA')\n",
    "data[['TotalUseTypeNumber'] + gfa_features].head(10)\n",
    "Out[38]:\n",
    "\n",
    "TotalUseTypeNumber\n",
    "PropertyGFATotal\n",
    "PropertyGFAParking\n",
    "PropertyGFABuilding(s)\n",
    "LargestPropertyUseTypeGFA\n",
    "SecondLargestPropertyUseTypeGFA\n",
    "ThirdLargestPropertyUseTypeGFA\n",
    "0\n",
    "1\n",
    "111077.0\n",
    "0.0\n",
    "111077.0\n",
    "NaN\n",
    "NaN\n",
    "NaN\n",
    "1\n",
    "1\n",
    "98370.0\n",
    "25920.0\n",
    "72450.0\n",
    "98370.0\n",
    "NaN\n",
    "NaN\n",
    "2\n",
    "5\n",
    "193788.0\n",
    "37854.0\n",
    "155934.0\n",
    "138672.0\n",
    "47539.0\n",
    "11166.0\n",
    "3\n",
    "2\n",
    "76598.0\n",
    "21410.0\n",
    "55188.0\n",
    "55188.0\n",
    "21410.0\n",
    "NaN\n",
    "4\n",
    "2\n",
    "186971.0\n",
    "0.0\n",
    "186971.0\n",
    "186977.0\n",
    "115477.0\n",
    "NaN\n",
    "5\n",
    "1\n",
    "66968.0\n",
    "0.0\n",
    "66968.0\n",
    "NaN\n",
    "NaN\n",
    "NaN\n",
    "6\n",
    "2\n",
    "434475.0\n",
    "250000.0\n",
    "184475.0\n",
    "434475.0\n",
    "250000.0\n",
    "NaN\n",
    "7\n",
    "2\n",
    "192960.0\n",
    "32160.0\n",
    "160800.0\n",
    "135173.0\n",
    "32000.0\n",
    "NaN\n",
    "8\n",
    "1\n",
    "54171.0\n",
    "0.0\n",
    "54171.0\n",
    "NaN\n",
    "NaN\n",
    "NaN\n",
    "9\n",
    "3\n",
    "83448.0\n",
    "15479.0\n",
    "67969.0\n",
    "42527.0\n",
    "27961.0\n",
    "529.0\n",
    "In [39]:\n",
    "\n",
    "\n",
    "#On calcule les ratios\n",
    "data['GFABuildingRate'] = (round((data['PropertyGFABuilding(s)'].fillna(0)\n",
    "                                  /data['PropertyGFATotal'].fillna(0)),5))\n",
    "data['GFAParkingRate'] = (round((data['PropertyGFAParking'].fillna(0)\n",
    "                                 /data['PropertyGFATotal'].fillna(0)),5))\n",
    "\n",
    "#On supprime les variables inutiles\n",
    "data.drop(['LargestPropertyUseTypeGFA', \n",
    "           'SecondLargestPropertyUseTypeGFA',\n",
    "           'SecondLargestPropertyUseType',\n",
    "           'ThirdLargestPropertyUseTypeGFA',\n",
    "           'ThirdLargestPropertyUseType',\n",
    "           'PropertyGFAParking',\n",
    "           'PropertyGFABuilding(s)'],\n",
    "         axis=1, inplace=True)\n",
    "\n",
    "#On complète les usages de la partie la plus large\n",
    "data['LargestPropertyUseType'] = data['LargestPropertyUseType'].fillna(\"Unknown\")\n",
    "data['NumberofFloors'] = data['NumberofFloors'].fillna(1)\n",
    "\n",
    "\n",
    "Nous pouvons également calculer la surface moyenne par bâtiment et par étage :\n",
    "In [40]:\n",
    "\n",
    "\n",
    "data['GFAPerBuilding'] = round((data['PropertyGFATotal'] / data['NumberofBuildings']),3)\n",
    "data['GFAPerFloor'] = round((data['PropertyGFATotal'] / data['NumberofFloors']),3)\n",
    "In [41]:\n",
    "\n",
    "\n",
    "data.info()\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "Int64Index: 1678 entries, 0 to 1697\n",
    "Data columns (total 36 columns):\n",
    " #   Column                         Non-Null Count  Dtype  \n",
    "---  ------                         --------------  -----  \n",
    " 0   OSEBuildingID                  1678 non-null   int64  \n",
    " 1   DataYear                       1678 non-null   int64  \n",
    " 2   BuildingType                   1678 non-null   object \n",
    " 3   PrimaryPropertyType            1678 non-null   object \n",
    " 4   PropertyName                   1678 non-null   object \n",
    " 5   Address                        1678 non-null   object \n",
    " 6   City                           1678 non-null   object \n",
    " 7   State                          1678 non-null   object \n",
    " 8   ZipCode                        1662 non-null   object \n",
    " 9   TaxParcelIdentificationNumber  1678 non-null   object \n",
    " 10  CouncilDistrictCode            1678 non-null   int64  \n",
    " 11  Neighborhood                   1678 non-null   object \n",
    " 12  Latitude                       1678 non-null   object \n",
    " 13  Longitude                      1678 non-null   object \n",
    " 14  LargestPropertyUseType         1678 non-null   object \n",
    " 15  YearsENERGYSTARCertified       99 non-null     object \n",
    " 16  DefaultData                    1678 non-null   object \n",
    " 17  ComplianceStatus               1678 non-null   object \n",
    " 18  NumberofBuildings              1678 non-null   float64\n",
    " 19  NumberofFloors                 1678 non-null   float64\n",
    " 20  PropertyGFATotal               1678 non-null   float64\n",
    " 21  ENERGYSTARScore                1141 non-null   float64\n",
    " 22  SiteEUI(kBtu/sf)               1678 non-null   float64\n",
    " 23  SourceEUI(kBtu/sf)             1678 non-null   float64\n",
    " 24  SiteEnergyUse(kBtu)            1678 non-null   float64\n",
    " 25  SteamUse(kBtu)                 1678 non-null   float64\n",
    " 26  Electricity(kBtu)              1678 non-null   float64\n",
    " 27  NaturalGas(kBtu)               1678 non-null   float64\n",
    " 28  TotalGHGEmissions              1678 non-null   float64\n",
    " 29  GHGEmissionsIntensity          1678 non-null   float64\n",
    " 30  BuildingAge                    1678 non-null   int64  \n",
    " 31  TotalUseTypeNumber             1678 non-null   int64  \n",
    " 32  GFABuildingRate                1678 non-null   float64\n",
    " 33  GFAParkingRate                 1678 non-null   float64\n",
    " 34  GFAPerBuilding                 1678 non-null   float64\n",
    " 35  GFAPerFloor                    1678 non-null   float64\n",
    "dtypes: float64(16), int64(5), object(15)\n",
    "memory usage: 485.0+ KB\n",
    "\n",
    "\n",
    "Les données sont à présent bien complétées. Nous allons vérifier l'impact de ce feature engineering sur la matrice des corrélations linéaires :\n",
    "In [42]:\n",
    "\n",
    "\n",
    "corr = data.corr()\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "ax = sns.heatmap(corr, annot=True, fmt=\".2f\", annot_kws={'size':8}, \n",
    "                 mask=mask, center=0, cmap=\"coolwarm\")\n",
    "plt.title(f\"Heatmap des corrélations linéaires\\n\", \n",
    "          fontdict=font_title)\n",
    "plt.show()\n",
    "\n",
    "In [43]:\n",
    "\n",
    "\n",
    "threshold = 0.7\n",
    "corr_pairs = corr.unstack().sort_values(kind=\"quicksort\")\n",
    "strong_corr = (pd.DataFrame(corr_pairs[(abs(corr_pairs) > threshold)])\n",
    "               .reset_index().rename(columns={0:'corr_coeff'}))\n",
    "strong_corr = strong_corr[(strong_corr.index%2 == 0) & (strong_corr['level_0'] != strong_corr['level_1'])]\n",
    "strong_corr.sort_values('corr_coeff', ascending=False)\n",
    "Out[43]:\n",
    "\n",
    "level_0\n",
    "level_1\n",
    "corr_coeff\n",
    "20\n",
    "Electricity(kBtu)\n",
    "SiteEnergyUse(kBtu)\n",
    "0.956707\n",
    "18\n",
    "SourceEUI(kBtu/sf)\n",
    "SiteEUI(kBtu/sf)\n",
    "0.951789\n",
    "16\n",
    "Electricity(kBtu)\n",
    "PropertyGFATotal\n",
    "0.867333\n",
    "14\n",
    "TotalGHGEmissions\n",
    "SiteEnergyUse(kBtu)\n",
    "0.862087\n",
    "12\n",
    "PropertyGFATotal\n",
    "SiteEnergyUse(kBtu)\n",
    "0.810407\n",
    "10\n",
    "NumberofBuildings\n",
    "Electricity(kBtu)\n",
    "0.775949\n",
    "8\n",
    "NumberofBuildings\n",
    "PropertyGFATotal\n",
    "0.775589\n",
    "6\n",
    "NaturalGas(kBtu)\n",
    "TotalGHGEmissions\n",
    "0.736970\n",
    "4\n",
    "NumberofBuildings\n",
    "SiteEnergyUse(kBtu)\n",
    "0.724128\n",
    "2\n",
    "GHGEmissionsIntensity\n",
    "SiteEUI(kBtu/sf)\n",
    "0.703791\n",
    "0\n",
    "GFAParkingRate\n",
    "GFABuildingRate\n",
    "-1.000000\n",
    "\n",
    "\n",
    "Vérification de multicolinéarité avec le VIF (Variance Inflation Factor) : VIF=11−R2���=11−�2\n",
    "In [44]:\n",
    "\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "strong_corr_features = list(set(list(strong_corr['level_0'].values) + list(strong_corr['level_1'].values)))\n",
    "X = data[strong_corr_features].replace([np.inf, -np.inf], np.nan)\n",
    "X = X.dropna()\n",
    "\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) \n",
    "                   for i in range(len(X.columns))]\n",
    "vif_data[vif_data['VIF'] > 5]\n",
    "Out[44]:\n",
    "\n",
    "feature\n",
    "VIF\n",
    "0\n",
    "TotalGHGEmissions\n",
    "75.899891\n",
    "1\n",
    "GHGEmissionsIntensity\n",
    "8.421085\n",
    "2\n",
    "PropertyGFATotal\n",
    "5.876687\n",
    "4\n",
    "Electricity(kBtu)\n",
    "332.919384\n",
    "5\n",
    "SiteEUI(kBtu/sf)\n",
    "53.300640\n",
    "6\n",
    "SiteEnergyUse(kBtu)\n",
    "733.951440\n",
    "7\n",
    "SourceEUI(kBtu/sf)\n",
    "37.647406\n",
    "8\n",
    "NumberofBuildings\n",
    "8.603262\n",
    "10\n",
    "NaturalGas(kBtu)\n",
    "8.927115\n",
    "\n",
    "\n",
    "Des scores VIF supérieur à 5 indiquent généralement une forte multicolinéarité. Ces variables fortement corrélées risquent d'impacter nos modèles.\n",
    "Les features suffixées EUI(kBtu/sf), sont des variables dont les valeurs sont ramenées à la surface par étage. Nous allons les supprimer car nous avons créer des variables pouvant permettre de ramener nos données à l'étage ou au building. Idem pour la variable GHGEmissionsIntensity\n",
    "In [45]:\n",
    "\n",
    "\n",
    "Eui_features = search_componant(data, suffix='EUI(kBtu/sf)') + ['GHGEmissionsIntensity']\n",
    "data.drop(Eui_features, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "2.4. Analyse des variables à prédire\n",
    "Pour rappel, les 2 variables à prédire dans le cadre de notre mission sont :\n",
    "TotalGHGEmissions\n",
    "SiteEnergyUse(kBtu)\n",
    "Nous allons donc réaliser quelques analyses exploratoires sur ces features :\n",
    "In [46]:\n",
    "\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, sharex=False, sharey=False, figsize=(20,8))\n",
    "left, width = 0, 1\n",
    "bottom, height = 0, 1\n",
    "right = left + width\n",
    "top = bottom + height\n",
    "\n",
    "sns.histplot(data=data, x=\"TotalGHGEmissions\", kde=True, ax=axes[0], color=\"#9C3E2D\", alpha=0.6)\n",
    "axes[0].set_title(\"Données d'emission de CO2 globales\", color='#2cb7b0')\n",
    "\n",
    "#Test de Kolmogorov-Smirnov\n",
    "kstest = stats.kstest(data['TotalGHGEmissions'].notnull(),'norm')\n",
    "axes[0].text(right, top, 'Test Kolmogorov-Smirnov \\n Pvalue: {:.2} \\n Stat: {:.2}'.format(kstest.pvalue, kstest.statistic),\n",
    "            horizontalalignment='right',\n",
    "            verticalalignment='top',\n",
    "            style='italic', transform=axes[0].transAxes, fontsize = 12,\n",
    "            bbox={'facecolor':'#00afe6', 'alpha':0.5, 'pad':0})\n",
    "\n",
    "sns.histplot(data=data[(data['TotalGHGEmissions']< 1000)], x=\"TotalGHGEmissions\", kde=True, ax=axes[1], color=\"#9C3E2D\", alpha=0.6)\n",
    "axes[1].set_title(\"Données d'emission de CO2 zoomées\", color='#2cb7b0')\n",
    "\n",
    "plt.suptitle(\"Distribution des emissions de CO2 relevées (2015-2016)\", \n",
    "             fontdict=font_title, fontsize=22)\n",
    "plt.show()\n",
    "\n",
    "In [47]:\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, sharex=False, sharey=False, figsize=(20,8))\n",
    "\n",
    "sns.histplot(data=data, x=\"SiteEnergyUse(kBtu)\", kde=True, ax=axes[0], color=\"#6D9C0E\", alpha=0.6)\n",
    "axes[0].set_title(\"Données de consommation d'énergie globales\", color='#2cb7b0')\n",
    "\n",
    "#Test de Kolmogorov-Smirnov\n",
    "kstest = stats.kstest(data['SiteEnergyUse(kBtu)'].notnull(),'norm')\n",
    "axes[0].text(right, top, 'Test Kolmogorov-Smirnov \\n Pvalue: {:.2} \\n Stat: {:.2}'.format(kstest.pvalue, kstest.statistic),\n",
    "            horizontalalignment='right',\n",
    "            verticalalignment='top',\n",
    "            style='italic', transform=axes[0].transAxes, fontsize = 12,\n",
    "            bbox={'facecolor':'#00afe6', 'alpha':0.5, 'pad':0})\n",
    "\n",
    "sns.histplot(data=data[(data['SiteEnergyUse(kBtu)']< 0.3*10**8)], x=\"SiteEnergyUse(kBtu)\", kde=True, ax=axes[1], color=\"#6D9C0E\", alpha=0.6)\n",
    "axes[1].set_title(\"Données de consommation d'énergie zoomées\", color='#2cb7b0')\n",
    "\n",
    "plt.suptitle(\"Distribution des consommation d'énergie relevées (2015-2016)\", \n",
    "             fontdict=font_title, fontsize=22)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "En se basant sur les projections obtenus et les résultats des tests de Kolmogorov-Smirnov (Pvalue < au niveau de test de 5%) on rejette donc l'hypothèse de normalité des distributions de ces variables.\n",
    "Projettons à présent les scatterplots des distribition de ces 2 variables entre elles :\n",
    "In [48]:\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, sharex=False, sharey=False, figsize=(20,8))\n",
    "sns.scatterplot(data=data, x=\"TotalGHGEmissions\", y=\"SiteEnergyUse(kBtu)\", ax=axes[0])\n",
    "axes[0].set_title(\"Données globales\", color='#2cb7b0')\n",
    "sns.scatterplot(data=data[(data['TotalGHGEmissions'] < 5000)], x=\"TotalGHGEmissions\", y=\"SiteEnergyUse(kBtu)\", ax=axes[1])\n",
    "axes[1].set_title(\"Données zoomées\", color='#2cb7b0')\n",
    "plt.suptitle(\"Répartition des données de consommation d'énergie vs emissions de CO2\", fontdict=font_title, fontsize=22)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "on remarque ici que la répartion des données d'emission de CO2 en fonction de la consommation d'énergie ne suivent pas uniquement 1 seule droite de régression linéaire si l'on zoom sur les données les plus représentées.\n",
    "Regardons à présent si les coordonnées géographiques ont un impact sur les rejets et consommations. Pour cela, afin d'éviter les corrélations fortes entre Latitude et Longitude, nous allons calculer la distance Harversine entre chaque point de coordonnées et le centre de Seattle :\n",
    "In [49]:\n",
    "\n",
    "\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "#Coordonnées du centre de Seattle\n",
    "seattle_lat = 47.6062\n",
    "seattle_lon = -122.3321\n",
    "\n",
    "def haversine_distance(lat1, lng1, lat2, lng2, degrees=True):\n",
    "    r = 3956 # rayon de la Terre en miles\n",
    "    \n",
    "    if degrees:\n",
    "        lat1, lng1, lat2, lng2 = map(radians, [lat1, lng1, lat2, lng2])\n",
    "    \n",
    "    # Formule Haversine\n",
    "    dlng = lng2 - lng1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlng/2)**2\n",
    "    d = 2 * r * asin(sqrt(a))  \n",
    "\n",
    "    return d\n",
    "In [50]:\n",
    "\n",
    "\n",
    "#Calcul des distance au centre de Seattle pour chaque point\n",
    "data['harvesine_distance'] = [haversine_distance(seattle_lat, seattle_lon, x, y) \n",
    "                              for x, y in zip(data.Latitude.astype(float), data.Longitude.astype(float))]\n",
    "In [51]:\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, sharex=False, sharey=False, figsize=(20,8))\n",
    "sns.scatterplot(data=data, y=\"TotalGHGEmissions\", x=\"harvesine_distance\", color=\"#9C3E2D\", ax=axes[0])\n",
    "axes[0].set_title(\"Données globales\", color='#2cb7b0')\n",
    "sns.histplot(data=data[(data['TotalGHGEmissions'] < 2500)], y=\"TotalGHGEmissions\", \n",
    "                x=\"harvesine_distance\", color=\"#9C3E2D\", ax=axes[1])\n",
    "axes[1].set_title(\"Données zoomées\", color='#2cb7b0')\n",
    "plt.suptitle(\"Répartition des données d'emissions de CO2 en fonction des coordonnées géographiques\", \n",
    "             fontdict=font_title, fontsize=22)\n",
    "plt.show()\n",
    "\n",
    "In [52]:\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, sharex=False, sharey=False, figsize=(20,8))\n",
    "sns.scatterplot(data=data, y=\"SiteEnergyUse(kBtu)\", x=\"harvesine_distance\", color=\"#6D9C0E\", ax=axes[0])\n",
    "axes[0].set_title(\"Données globales\", color='#2cb7b0')\n",
    "sns.histplot(data=data[(data['SiteEnergyUse(kBtu)'] < 2*10**8)], y=\"SiteEnergyUse(kBtu)\", \n",
    "                x=\"harvesine_distance\", color=\"#6D9C0E\", ax=axes[1])\n",
    "axes[1].set_title(\"Données zoomées\", color='#2cb7b0')\n",
    "plt.suptitle(\"Répartition des données d'emissions de CO2 en fonction des coordonnées géographiques\", \n",
    "             fontdict=font_title, fontsize=22)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "En regardant ces projections, il semble que les coordonnées géographiques (donc les adresses des bâtiments) puissent avoir un impact sur les consommations d'égergie et rejets de CO2.\n",
    "D'autre part, la latitude et la longitude étant 2 variables fortement corrélées dans notre jeu de données, nous allons supprimer ces 2 colonnes pour conserver uniquement ce point de coordonnée unique Harvesine (en fin de Notebook).\n",
    "\n",
    "\n",
    "Nous allons à présent regarder la répartition de ces 2 variables en fonction du type de bâtiement.\n",
    "In [53]:\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, sharex=False, sharey=False, figsize=(20,8))\n",
    "sns.barplot(x='BuildingType',y='TotalGHGEmissions',data=data, ax=axes[0])\n",
    "sns.barplot(x='BuildingType',y='SiteEnergyUse(kBtu)',data=data, ax=axes[1])\n",
    "plt.suptitle(\"Répartition de la consommation d'énergie et emissions de CO2 en fonction du type de bâtiment\", \n",
    "             fontdict=font_title, fontsize=18)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "Sur ces diagrammes en barre, les campus se démarquent largement en terme de consommation et de rejets de CO2. Regardons à présent si l'âge des bâtiments a un impact sur les émissions de CO2 :\n",
    "In [54]:\n",
    "\n",
    "\n",
    "bins = pd.IntervalIndex.from_tuples([(0, 10), (10, 20), (20, 30), (30, 40), (40, 50), \n",
    "                                     (50, 60), (60, 70), (70,80), (80,90), (90,100), \n",
    "                                     (100,110), (110,120)])\n",
    "\n",
    "sns.catplot(\n",
    "    data=data, kind=\"bar\",\n",
    "    x=pd.cut(data['BuildingAge'], bins=bins), y=\"TotalGHGEmissions\",\n",
    "    ci=None, color=\"#9C3E2D\", alpha=.6,\n",
    "    height=7, aspect=2\n",
    ")\n",
    "plt.title(\"Influence de l'âge des bâtiments sur les émissions de CO2\", fontdict=font_title)\n",
    "plt.show()\n",
    "\n",
    "In [55]:\n",
    "\n",
    "\n",
    "sns.catplot(\n",
    "    data=data, kind=\"bar\",\n",
    "    x=pd.cut(data['BuildingAge'], bins=bins), y=\"SiteEnergyUse(kBtu)\",\n",
    "    ci=None, color=\"#6D9C0E\", alpha=.6,\n",
    "    height=7, aspect=2\n",
    ")\n",
    "plt.title(\"Influence de l'âge des bâtiments sur les consommations d'énergie\", fontdict=font_title)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "Les bâtiments de moins de 30 ans semblent avoir des consommations d'énergie et rejets de CO2 plus important que les buildings anciens, alors même que la variable BuildingAge n'est pas fortement corrélée à d'autres features (comme la taille des bâtiments par exemple).\n",
    "\n",
    "\n",
    "3. Dernières étapes de nettoyage\n",
    "Nous allons éliminer certaines variables qui ne seront pas utiles pour nos modélisations et vérifier les données incomplètes identifiées dans le jeu de données initial.\n",
    "In [56]:\n",
    "\n",
    "\n",
    "data.info()\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "Int64Index: 1678 entries, 0 to 1697\n",
    "Data columns (total 34 columns):\n",
    " #   Column                         Non-Null Count  Dtype  \n",
    "---  ------                         --------------  -----  \n",
    " 0   OSEBuildingID                  1678 non-null   int64  \n",
    " 1   DataYear                       1678 non-null   int64  \n",
    " 2   BuildingType                   1678 non-null   object \n",
    " 3   PrimaryPropertyType            1678 non-null   object \n",
    " 4   PropertyName                   1678 non-null   object \n",
    " 5   Address                        1678 non-null   object \n",
    " 6   City                           1678 non-null   object \n",
    " 7   State                          1678 non-null   object \n",
    " 8   ZipCode                        1662 non-null   object \n",
    " 9   TaxParcelIdentificationNumber  1678 non-null   object \n",
    " 10  CouncilDistrictCode            1678 non-null   int64  \n",
    " 11  Neighborhood                   1678 non-null   object \n",
    " 12  Latitude                       1678 non-null   object \n",
    " 13  Longitude                      1678 non-null   object \n",
    " 14  LargestPropertyUseType         1678 non-null   object \n",
    " 15  YearsENERGYSTARCertified       99 non-null     object \n",
    " 16  DefaultData                    1678 non-null   object \n",
    " 17  ComplianceStatus               1678 non-null   object \n",
    " 18  NumberofBuildings              1678 non-null   float64\n",
    " 19  NumberofFloors                 1678 non-null   float64\n",
    " 20  PropertyGFATotal               1678 non-null   float64\n",
    " 21  ENERGYSTARScore                1141 non-null   float64\n",
    " 22  SiteEnergyUse(kBtu)            1678 non-null   float64\n",
    " 23  SteamUse(kBtu)                 1678 non-null   float64\n",
    " 24  Electricity(kBtu)              1678 non-null   float64\n",
    " 25  NaturalGas(kBtu)               1678 non-null   float64\n",
    " 26  TotalGHGEmissions              1678 non-null   float64\n",
    " 27  BuildingAge                    1678 non-null   int64  \n",
    " 28  TotalUseTypeNumber             1678 non-null   int64  \n",
    " 29  GFABuildingRate                1678 non-null   float64\n",
    " 30  GFAParkingRate                 1678 non-null   float64\n",
    " 31  GFAPerBuilding                 1678 non-null   float64\n",
    " 32  GFAPerFloor                    1678 non-null   float64\n",
    " 33  harvesine_distance             1678 non-null   float64\n",
    "dtypes: float64(14), int64(5), object(15)\n",
    "memory usage: 523.4+ KB\n",
    "\n",
    "\n",
    "Vérifions la variable ComplianceStatus qui représente la conformité des données relevées :\n",
    "In [57]:\n",
    "\n",
    "\n",
    "data['ComplianceStatus'].unique()\n",
    "Out[57]:\n",
    "array(['Compliant', 'Error - Correct Default Data', 'Missing Data',\n",
    "       'Non-Compliant'], dtype=object)\n",
    "In [58]:\n",
    "\n",
    "\n",
    "print(\"Nombre de ligne identifiées comme non conforme : {}.\".format(data[data['ComplianceStatus'] != \"Compliant\"].shape[0]))\n",
    "Nombre de ligne identifiées comme non conforme : 103.\n",
    "In [59]:\n",
    "\n",
    "\n",
    "data = data[data['ComplianceStatus'] == \"Compliant\"]\n",
    "\n",
    "\n",
    "Nous allons ensuite supprimer les variables DefaultData, ComplianceStatus, TaxParcelIdentificationNumber, CouncilDistrictCode, City\n",
    "In [60]:\n",
    "\n",
    "\n",
    "data = data.drop(['DefaultData','ComplianceStatus', 'City',\n",
    "                  'TaxParcelIdentificationNumber','CouncilDistrictCode'], axis=1)\n",
    "\n",
    "\n",
    "4. Projection des établissements sur la carte de Seattle\n",
    "In [61]:\n",
    "\n",
    "\n",
    "linkcode\n",
    "import folium\n",
    "import folium.plugins\n",
    "\n",
    "seattle_map = folium.Map(location=[seattle_lat, seattle_lon], zoom_start=11)\n",
    "\n",
    "#Clusters\n",
    "marker_cluster = folium.plugins.MarkerCluster().add_to(seattle_map)\n",
    "for lat, lng, in zip(data.Latitude, data.Longitude):\n",
    "    folium.Marker(location=[lat, lng]).add_to(marker_cluster)\n",
    "\n",
    "seattle_map\n",
    "Out[61]:\n",
    "Make this Notebook Trusted to load map: File -> Trust Notebook\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
